{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Iqu-_1s7UWpd"
   },
   "source": [
    "# **Case 1: Reformulation based on Short Sentence Transformer Embedding**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ByEL7-ISUPuY"
   },
   "source": [
    "Based on toy examples: \"Toyota\" and \"Toyota Camry\" (\"Specification\" reformulation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I5wx-EeYU2RJ"
   },
   "source": [
    "# 1. Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mACyEKAKUwnd"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TwI5h56NU-AB"
   },
   "source": [
    "# 2. Define query simlarity calculation function and test with toy examples\n",
    "Cosine similarity: -1 to 1 <br>\n",
    "\n",
    "*   1: similar <br>\n",
    "*   0: no relationshiip <br>\n",
    "*   -1: dissimilar (opposite)  <br>\n",
    "\n",
    "Edit distance based similarity: 0 to 1 <br>\n",
    "*   1: similar <br>\n",
    "*   0: no relationship <br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "srG4OHFaTtkR"
   },
   "outputs": [],
   "source": [
    "##### Cosine Similarity based on sentence transformer embeddings\n",
    "\n",
    "### Query reformulation based on sentence transformer embeddings\n",
    "def calculate_query_similarity(query1, query2, threshold=0.6):\n",
    "    # Load the sentence transformer model\n",
    "    model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "    # Encode the queries\n",
    "    query1_embedding = model.encode([query1])\n",
    "    query2_embedding = model.encode([query2])\n",
    "\n",
    "    # Calculate cosine similarity\n",
    "    similarity = cosine_similarity(query1_embedding, query2_embedding)[0][0]\n",
    "\n",
    "    # Judge if query2 is a reformulation of query1\n",
    "    is_reformulation = similarity >= threshold\n",
    "\n",
    "    return similarity, is_reformulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 597,
     "referenced_widgets": [
      "d942ce0c4b0749a9bc21cad48d4a12c3",
      "5b96061876334054b431388a2d30c3bc",
      "8d286b8d351b4661957b248454ac384a",
      "f544bd5a45014c1aa9d0c84db907d79b",
      "95e7e08369434fd68f7e3ef255c495f2",
      "3aab18c3624643c3bd601678277d301b",
      "4dd9a18871ee40778fe25e1bc1d4d49a",
      "736b6db745c344a3be1c586a91de87d5",
      "73397804689a44e7a08f97a77b15718f",
      "917c73ce3c56437c9d19d7c9e1d31e8a",
      "ead0d4890418450596efd695dcb71b9d",
      "bf070cf056224a8f95c34622f41fc6fc",
      "0fbba50138de449ab6ec6d42e428ec32",
      "c52bc3c8ccdf4cffa2fea9ada5ba7a33",
      "f18aa5c039ae42f5a60a7b7610b106e2",
      "1860a0b181be4cd092a2a5df66f54d0a",
      "d69e2d1f144a4e98aaee4801ecf23388",
      "13c96cd167cf4c6f8f79a67a5931f0b6",
      "44e23883a4f94fb8934505d41bad1c6b",
      "18930e8b270d4f15ae27dc39286011b7",
      "037fc5360434438c9ed2fc7014a7b8e4",
      "e1b5c0a63baf4120b8cd1eb4089644b5",
      "ff6f0d5f85b44dd28120aa29be427b7e",
      "68479a0910924d5b8709b649eb8d4a3e",
      "66991ff46d1a4ffe93814815e3e24305",
      "f30eb357dada4f10acdd49febc786b17",
      "6e7cb83d2c7c4bc38ebebc3db0ebc1cd",
      "821a0a78cae84490b44bdcbc5b7f96de",
      "f46aa44011eb46c3bfec7c20a3b75996",
      "07ea74b4bc514dd0b5d7798490aa87d8",
      "809c057174a047608c699a4349a6365a",
      "fbbdf9eb9a9b4506b2f5750f3ca11259",
      "f8ea3fd60e8141bebd8e484c7e7eccdc",
      "8e0ce143287149e5b5388920130025d3",
      "d63cf187a43d4158b8798127e9fec1b0",
      "2295d32c6aac4630aae72af37e396bcf",
      "3fb620a07ec34c3690990f5814c6e340",
      "fb3e2dee5e624c14a4ae5365a2069bbd",
      "0e1fbba24387412790ee0b26205dad05",
      "4c713743ef0e4d509f003ec919c01b75",
      "18721592b02a4d4191262513957ab116",
      "5db717edaff94f909b1aee14993b84b9",
      "5bc3929ac4454417bbf900923439d15c",
      "6d672771ce264cb8afb7040313c9acbb",
      "7f452e9760d14527bcd26c5a106af127",
      "c9afaab3b02c475bafae08cecdfd2076",
      "8d11d315e3cb4f288465668834a668a8",
      "120673d980d14d03b8f1f7011f27792e",
      "645ed719e97f492289fa2de9067153f7",
      "28a04c6ef27e4780ad910820ca4442b7",
      "e5196b2d0abe48079c98be76e707d815",
      "d98607f8a9544bc2a0099bca6e95599d",
      "d43442b0d5944b57bdaead39c3030c76",
      "1ad0d4212aa0427b94cf2fd9e4b37596",
      "77ec3677f70343fd97fce2ecbdd92b2e",
      "f46f3ebfaf4e4ac6b6e76e874eb4f837",
      "4cd3642e8f1a4e6c99db554da8b7fea7",
      "cb934c4e97d5415c98a57c08da37663d",
      "fcef3ecf3ac44ec6b17544db7c6da2d6",
      "74f538b609884ab8ae72442a1d89fbb4",
      "9341902f80334220a609bc2fdfbe2759",
      "90a40d0c40c540fda41e2df8056e4bf6",
      "441ec8d1e0244040a797644273c3ce6b",
      "246e99e557db43b6bd66558d48ab091b",
      "7863417124c44db6b807c3053f1586ab",
      "f0fb68c17041471ca7c1c5ea8847b0c6",
      "8a9e46fcfa6c442d9c0c7d80eeaadbea",
      "0066a634ebf742249373ff5b10220747",
      "6663dd96608b41b0833aa467c4710e28",
      "01d1c19feb74494f9ea1bf27be86a64a",
      "d232dfdd181a4785b96920cfea339d83",
      "cd93c9d6300b45d3a2325f9e99581605",
      "b4c6fb1d54de4dc7b8de240b0754c4fa",
      "2f212df4a54b493a9907f82817c0fa87",
      "a36264cc0b4043a19aa63cca647016f5",
      "1e96c1cd59a84b04af6b0f6c7e4188d2",
      "3cb8dbbb042443b5bb6166e90623602d",
      "0ae45978c40e4b1d9b4ae96f5e65a9e3",
      "8d0489321a47465fa11fd94a6de1afc1",
      "a00f6f9fcafa4de8ab26f6f83ed60cc6",
      "d1b8807284d648a7b07477983520caf1",
      "588455ea60354486b6453de66695c8a6",
      "c6658bcedf7240a99f29ef53f5718251",
      "3d087ad66b0f4a3db56b9b3fd39cd204",
      "c96ed8feb539489eb1e50fc98f6d4174",
      "96fd43007703433fa05bff87c02a776e",
      "52abe6cb73d040a4b16f3e8fd1203a69",
      "c4dfd269c878458785c4c12c805f64a4",
      "ed5cb64279d842229609d04381cef6a7",
      "a4b492b827e04ec1be3cca5ee272fde3",
      "cb0cdf2685f34ce4b6e1ac488140dc5d",
      "7f014f8ff5f94bf68e3087c010ad585e",
      "742b73e09d59407fa0b24d7d0d504ec5",
      "c5422c7af96a4d018f56e168f572737a",
      "4ab9a3dfe3c4479c8f21a1ab0de4fcc4",
      "90ebadc0f8c246208cb37ff78a894170",
      "28ba8d72735f4bd9b1eb087bb1114b4b",
      "c86500e4ac27464bb5aaaf283a04b199",
      "d0a042edd50945c78ee27d5b3a710024",
      "19a16dc0193242eab57982d2229df2ed",
      "6d60c5e1bc3048329f5634dfb3864a86",
      "e3e43ff6c516439aba468f29173e80a6",
      "540c37f9e1144a3dbf25886441a4a795",
      "7b008837a23147be87c34bb2024a08c1",
      "c90f096f75ae4bb4b7b7c779013061b6",
      "c944ed533ed54b4c8e975ccfa06d1548",
      "440ba382c35b4059a56f9764e77f0601",
      "e51cae7d8e4c406495831c0c559b85e0",
      "a48f422c0ed249edaa860f294090bb61",
      "e0c72f85b1104c4e94d660806a4ba3eb",
      "f824458b3b76491b9d7ef9db255883f3",
      "8c9d9de5a6054b2aa6eb6d365ef4aeb0",
      "e680f250921d4147926ef6951b95a14e",
      "c86c874bf562485bb1386fd7cefadf37",
      "486db6d9bc904e3da518c953854d3e07",
      "8e4f9868cdb147c584c30b2df1261729",
      "6b92bc84fc76441c87907569608049ee",
      "9b5fe3da2d3a4a2f9e8eed1223f4c4ef",
      "c077fd11e5e5455a932773fbf0d6485e",
      "7bc06e8a66a1473ba2f692f4a002aec8",
      "66c6d5949c914011a4549dd45e815fb1"
     ]
    },
    "id": "RyhaGTjZlek2",
    "outputId": "4efb2f72-9e15-4647-f1c7-cec052285fd1"
   },
   "outputs": [],
   "source": [
    "# Test the function: Not reformulation\n",
    "query1 = \"picture quality\"\n",
    "query2 = \"automobile quality\"\n",
    "\n",
    "similarity_score, is_reformulation = calculate_query_similarity(query1, query2)\n",
    "\n",
    "print(f\"Query 1: {query1}\")\n",
    "print(f\"Query 2: {query2}\")\n",
    "print(f\"Similarity Score: {similarity_score:.4f}\")\n",
    "print(f\"Is Query 2 a reformulation of Query 1? {is_reformulation}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "55v21mC0lm_b",
    "outputId": "2057ae48-e23f-4c58-8b09-73e1d8a151c9"
   },
   "outputs": [],
   "source": [
    "# Test the function: Query Reformulation\n",
    "query1 = \"Toyota\"\n",
    "query2 = \"Toyota Camry\"\n",
    "\n",
    "similarity_score, is_reformulation = calculate_query_similarity(query1, query2, 0.6)\n",
    "\n",
    "print(f\"Query 1: {query1}\")\n",
    "print(f\"Query 2: {query2}\")\n",
    "print(f\"Similarity Score: {similarity_score:.4f}\")\n",
    "print(f\"Is Query 2 a reformulation of Query 1? {is_reformulation}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IldYXFhkbM1k"
   },
   "outputs": [],
   "source": [
    "def edit_distance(query1: str, query2: str) -> int:\n",
    "    \"\"\"\n",
    "    Calculate the Levenshtein edit distance between two strings.\n",
    "\n",
    "    :param query1: First string\n",
    "    :param query2: Second string\n",
    "    :return: Edit distance (integer)\n",
    "    \"\"\"\n",
    "    m, n = len(query1), len(query2)\n",
    "\n",
    "    # Create a 2D array to store distances\n",
    "    dp = [[0] * (n + 1) for _ in range(m + 1)]\n",
    "\n",
    "    # Initialize base cases\n",
    "    for i in range(m + 1):\n",
    "        dp[i][0] = i  # Deletions\n",
    "    for j in range(n + 1):\n",
    "        dp[0][j] = j  # Insertions\n",
    "\n",
    "    # Compute edit distance\n",
    "    for i in range(1, m + 1):\n",
    "        for j in range(1, n + 1):\n",
    "            if query1[i - 1] == query2[j - 1]:\n",
    "                dp[i][j] = dp[i - 1][j - 1]  # No change needed\n",
    "            else:\n",
    "                dp[i][j] = min(\n",
    "                    dp[i - 1][j] + 1,    # Deletion\n",
    "                    dp[i][j - 1] + 1,    # Insertion\n",
    "                    dp[i - 1][j - 1] + 1 # Substitution\n",
    "                )\n",
    "\n",
    "    return dp[m][n]\n",
    "\n",
    "def edit_distance_query_similarity(query1: str, query2: str, threshold = 0.6) -> float:\n",
    "    \"\"\"\n",
    "    Compute similarity score between two queries based on edit distance.\n",
    "\n",
    "    :param query1: First query string\n",
    "    :param query2: Second query string\n",
    "    :return: Similarity score between 0 and 1\n",
    "    \"\"\"\n",
    "    # Compute edit distance\n",
    "    distance = edit_distance(query1, query2)\n",
    "\n",
    "    # Normalize similarity score\n",
    "    max_len = max(len(query1), len(query2))\n",
    "\n",
    "    # Avoid division by zero for empty strings\n",
    "    if max_len == 0:\n",
    "        return 1.0 if distance == 0 else 0.0\n",
    "\n",
    "    similarity = 1 - (distance / max_len)\n",
    "\n",
    "    # Judge if query2 is a reformulation of query1\n",
    "    is_reformulation = similarity >= threshold\n",
    "\n",
    "    return similarity, is_reformulation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vSrwHITYmNO5",
    "outputId": "4967a43b-4796-4f05-fd96-8825c542bab3"
   },
   "outputs": [],
   "source": [
    "# Example usage: Semantic reformulation\n",
    "query1 = \"fast food\"\n",
    "query2 = \"quick meal\"\n",
    "\n",
    "cosine_similarity_score, is_reformulation_cosine = calculate_query_similarity(query1, query2, 0.6)  # Calculate cosine similarity\n",
    "edit_distance_score, is_reformulation_edit = edit_distance_query_similarity(query1, query2, 0.6)  # Calculate edit distance similarity\n",
    "\n",
    "print(f\"Query 1: {query1}\")\n",
    "print(f\"Query 2: {query2}\")\n",
    "\n",
    "print(f\"Cosine Similarity Score: {cosine_similarity_score:.4f}\")\n",
    "print(f\"Is Query 2 a reformulation of Query 1? {is_reformulation_cosine}\")\n",
    "\n",
    "print(f\"Edit Distnce Similarity Score: {edit_distance_score:.4f}\")\n",
    "print(f\"Is Query 2 a reformulation of Query 1? {is_reformulation_edit}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mEXToLIcC26T",
    "outputId": "104a1544-e7ed-4f9a-913d-68026ccbcc30"
   },
   "outputs": [],
   "source": [
    "# Example query pairs\n",
    "query_pairs = [\n",
    "    (\"hello\", \"helo\"),               # Minor typo\n",
    "    (\"good morning\", \"morning good\"), # Word order change\n",
    "    (\"car rental\", \"rent a car\"),    # Semantic similarity but different words\n",
    "    (\"buy laptop\", \"purchase notebook\"), # Synonyms\n",
    "    (\"data science\", \"machine learning\"), # Related but different fields\n",
    "    (\"how to cook pasta\", \"pasta cooking instructions\"), # Different phrasing\n",
    "    (\"AI technology\", \"artificial intelligence\"), # Expanded abbreviation\n",
    "    (\"fast food\", \"quick meal\"), # Different wording, same meaning\n",
    "    (\"cheap flights\", \"low-cost airline tickets\"), # Paraphrased\n",
    "    (\"weather today\", \"current weather forecast\"), # Different structure\n",
    "\n",
    "]\n",
    "\n",
    "print(\"Similarity scores based on edit distance\")\n",
    "\n",
    "# Compute edit distance similarity for each pair (old reformulation metric)\n",
    "for q1, q2 in query_pairs:\n",
    "    similarity, is_reformulation = edit_distance_query_similarity(q1, q2, 0.6)\n",
    "    print(f\"Query1: {q1}, Query2: {q2}, Similarity: {similarity:.3f}, Is_Reformulation: {is_reformulation}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MziCxSB8pMil"
   },
   "source": [
    "Edit distance captures typos well, but fails with word reordering and semantic reformulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-l5728KKb3o0",
    "outputId": "fa88b6cf-197e-4996-955d-41d9b8fb3d30"
   },
   "outputs": [],
   "source": [
    "# Compute semantic similarity for each pair baesd on transformer embedding (new embedding-based reformulation metric)\n",
    "\n",
    "print(\"Similarity scores based on transfomer sentence embedding\")\n",
    "\n",
    "for q1, q2 in query_pairs:\n",
    "    similarity_score, is_reformulation = calculate_query_similarity(q1, q2, 0.6)\n",
    "    print(f\"Query1: {q1}, Query2: {q2}, Similarity: {similarity_score:.3f}, Is_Reformulation: {is_reformulation}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QBlL0cu8pWfm"
   },
   "source": [
    "In contrast, cosine simialirty from sentence embedding (semantic similarity) captures word reordering and semantic reformulation well. It did not capture typo, though (hello vs. helo.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FuM3B4ksVd-O"
   },
   "source": [
    "# **Case 2: Clustering based on Sentence Transfomer Embedding Vectors**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sL3E4MzTT-rV"
   },
   "source": [
    "(1) **Encode** a word to **embedding vectors** <br>\n",
    "(2) **Generate fake attributes** for testing <br>\n",
    "(3) Perform **clustering** based on cosine similarity distance: K-means <br>\n",
    "(4) **Assign** cluser membership to each attibute word <br>\n",
    "(5) Display **2D map** based on **TSNE** <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 742
    },
    "id": "gQHjskLpV0Ob",
    "outputId": "e41ef6b4-7203-4758-eec3-403245a8bb03"
   },
   "outputs": [],
   "source": [
    "# Step 1: Encode a word to embedding vectors using a short sentence transformer\n",
    "def encode_attributes(attributes, model_name=\"all-MiniLM-L6-v2\"):\n",
    "    \"\"\"Encodes a list of attribute names into embedding vectors.\"\"\"\n",
    "    model = SentenceTransformer(model_name)\n",
    "    embeddings = model.encode(attributes)\n",
    "    return embeddings\n",
    "\n",
    "# Step 2: Generate fake attributes for testing\n",
    "def generate_fake_attributes(n=20000):\n",
    "    \"\"\"Generates fake attribute names for testing.\"\"\"\n",
    "    base_words = [\"color\", \"size\", \"brand\", \"material\", \"quality\", \"durability\", \"price\", \"design\"]\n",
    "    attributes = [\n",
    "        f\"{random.choice(base_words)}_{random.randint(1, 10000)}\" for _ in range(n)\n",
    "    ]\n",
    "    return attributes\n",
    "\n",
    "# Step 3: Perform clustering based on cosine similarity\n",
    "def cluster_attributes(embeddings, num_clusters=8):\n",
    "    \"\"\"Clusters attributes using KMeans and cosine similarity.\"\"\"\n",
    "    # KMeans doesn't directly support cosine similarity, so normalize the embeddings\n",
    "    normalized_embeddings = embeddings / np.linalg.norm(embeddings, axis=1, keepdims=True)\n",
    "    kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
    "    cluster_labels = kmeans.fit_predict(normalized_embeddings)\n",
    "    return cluster_labels\n",
    "\n",
    "# Step 4: Assign membership numbers and test\n",
    "if __name__ == \"__main__\":\n",
    "    # Generate fake attributes\n",
    "    fake_attributes = generate_fake_attributes(n=20000)\n",
    "    print(f\"Generated {len(fake_attributes)} fake attributes.\")\n",
    "\n",
    "    # Encode attributes to embedding vectors\n",
    "    print(\"Encoding attributes...\")\n",
    "    embeddings = encode_attributes(fake_attributes)\n",
    "\n",
    "    # Perform clustering\n",
    "    print(\"Clustering attributes...\")\n",
    "    cluster_labels = cluster_attributes(embeddings, num_clusters=8)\n",
    "\n",
    "    # Display results: 10 sample cases\n",
    "    for i in range(10):\n",
    "        print(f\"Attribute: {fake_attributes[i]} -> Cluster: {cluster_labels[i]}\")\n",
    "\n",
    "    print(\"Clustering completed.\")\n",
    "\n",
    "# Step 5: Plot the clustering results with TSNE\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # Reduce dimensionality for visualization using t-SNE\n",
    "    tsne = TSNE(n_components=2, random_state=42)\n",
    "    embeddings_2d = tsne.fit_transform(embeddings)\n",
    "\n",
    "    # Plot the clustering results\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    for i in range(8):  # Assuming 8 clusters\n",
    "        plt.scatter(embeddings_2d[cluster_labels == i, 0], embeddings_2d[cluster_labels == i, 1], label=f\"Cluster {i}\", s=10)\n",
    "\n",
    "    plt.xlabel(\"t-SNE Dimension 1\")\n",
    "    plt.ylabel(\"t-SNE Dimension 2\")\n",
    "    plt.title(\"Clustering Results\")\n",
    "    plt.legend(loc='upper right', bbox_to_anchor=(1.3,1), fontsize='small') #adjust legend position and font size\n",
    "    plt.show()\n",
    "\n",
    "    print(\"Clustering completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FrHogEG1V2uV"
   },
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
